# For producer.py
KAFKA_CLIENT_ID=my-producer
QUEUE_BUFFERING_MAX_KBYTES = 51200  # 50 MB buffer size, greater than BATCH_MAX_RECORDS size (in MB)

# For consumer.py
KAFKA_GROUP_ID=my-consumer-group
CLICKHOUSE_HOST=127.0.0.1
CLICKHOUSE_PORT=9500
CLICKHOUSE_DATABASE=mydb

# For producer.py & consumer.py
KAFKA_BROKERS=127.0.0.1:9092
KAFKA_TOPIC=staging-bets
BATCH_MAX_RECORDS = 50000  # Each record is ~320 bytes * 50.000 => ~ 15 MB
AVRO_SCHEMA="{ \"type\": \"record\", \"name\": \"RiverTechRecord\", \"fields\": [ {\"name\": \"created_timestamp\", \"type\": \"string\"}, {\"name\": \"game_instance_id\", \"type\": \"int\"}, {\"name\": \"user_id\", \"type\": \"string\"}, {\"name\": \"game_id\", \"type\": \"int\"}, {\"name\": \"real_amount_bet\", \"type\": \"double\"}, {\"name\": \"bonus_amount_bet\", \"type\": [\"double\", \"null\"]}, {\"name\": \"real_amount_win\", \"type\": [\"double\", \"null\"]}, {\"name\": \"bonus_amount_win\", \"type\": \"double\"}, {\"name\": \"game_name\", \"type\": \"string\"}, {\"name\": \"provider\", \"type\": \"string\"} ] }"
